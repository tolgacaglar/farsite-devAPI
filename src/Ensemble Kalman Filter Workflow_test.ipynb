{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de901356-30f4-46aa-895f-f834710f5efa",
   "metadata": {},
   "source": [
    "# Ensemble Kalman Filter Workflow\n",
    "\n",
    "1. Available observation vector for $\\vec{y_{k+1}}$, and calculate the observation ensemble from the directional uncertainties based on the wind speed and direction. To calculate the uncertainty for each point of the perimeter:\n",
    "    1. Obtain the centroid $c_k = 1/M\\sum{y_k}$ where $M$ is the number of points.\n",
    "    2. Calculate vectors $\\vec{v_k^m}$ for each point from the centroid to the point where $m$ is the $m^{th}$ point in the perimeter\n",
    "    3. Obtain the wind speed and direction: $\\vec{u_k}$ from the closest weather station to the centroid\n",
    "    4. Uncertainty for each point $m$ is then $e_k^m = \\alpha \\left(1 - \\vec{v_k^m} \\cdot \\vec{u_k}\\right)$\n",
    "\n",
    "2. Given a state vector $x_k$ and uncertainties around each point $P_k$, generate an ensemble \n",
    "$$X_k = (x_k^1, x_k^2, \\cdots , x_k^N)$$\n",
    "    1. For the first timepoint $k=0$, the state vector is the first observation $(x_0 = y_0)$, and the ensemble is obtained from directional uncertainties assigned based on the wind speed and direction\n",
    "    2. **Question:** When creating the ensemble, do we preserve the mean $\\overline{x_k}$?\n",
    "    \n",
    "3. From the ensemble $X_k$, advance for each state vector $X_{k+1} = F(X_k, u_k)$, where $u_k$ \n",
    "\n",
    "4. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b5f10a-ee62-4ba4-aac3-0fe305e1bc0f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145b1582-6a79-497f-a6d3-6838d655a74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jovyan/farsite-devAPI/src/')\n",
    "sys.path.append('/home/jovyan/python-helper/src/')\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "\n",
    "import uuid\n",
    "import random\n",
    "\n",
    "import farsiteutils_v2 as futils\n",
    "from kalmanutils import calculate_uncertainties_observed, interpolate_perimeter\n",
    "\n",
    "from loggers import TimeEstimator\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac1bb62-56d4-4c93-aa7d-544952e3ab6f",
   "metadata": {},
   "source": [
    "## Default Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323345e2-6444-499f-87e2-c9bf65ae7a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTED_FIRE_DEFAULT = 'Maria2019'\n",
    "DATA_PATH = '/home/jovyan/data/'    # Folder to keep all the data while running the simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39840580-19e1-468d-85d2-bb17a1b28a29",
   "metadata": {},
   "source": [
    "## Select a fire\n",
    "\n",
    "```selected_fire``` variable holds the name of the fire selected. ```selected_fire = 'Maria2019'``` for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fee504-e3de-4596-9983-2851ed3ed383",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = futils.FilePaths(DATA_PATH)\n",
    "usr = futils.User(fp)\n",
    "\n",
    "unique_desc = usr.db.gdfignitionAll['description'].unique()\n",
    "print(f'Available fires are {unique_desc}')\n",
    "\n",
    "selected_fire = SELECTED_FIRE_DEFAULT\n",
    "print(f'{selected_fire} is selected.\\n')\n",
    "if (unique_desc == selected_fire).any():\n",
    "    print(f'{selected_fire} is found!')\n",
    "else:\n",
    "    raise ValueError(f'{selected_fire} not found in possible fire descriptions: {unique_desc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b04e271-eb7f-4ed7-a88e-b42f77bbd6ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "usr.db.gdfignition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8b2724-b39d-4548-8503-ff406bc70d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "referenceidx_lst = [usr.db.gdfignition.index[0]] + usr.db.gdfignition.index[-12:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c82488-5539-48f6-ac4b-b060e27939b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "import numpy as np\n",
    "\n",
    "def calculate_max_area_geom(multigeom):\n",
    "    max_area = 0\n",
    "    max_area_idx = 0\n",
    "    for ix, g in enumerate(multigeom.geoms):\n",
    "        if g.area > max_area:\n",
    "            max_area = g.area\n",
    "            max_area_idx = ix\n",
    "    return multigeom.geoms[max_area_idx]\n",
    "    \n",
    "\n",
    "class State:\n",
    "    def __init__(self, geom):\n",
    "        self.geom = geom\n",
    "        \n",
    "        # Initialize\n",
    "        self.vertices = self.calculate_vertices()\n",
    "        self.lengths = self.calculate_lengths()\n",
    "    def calculate_vertices(self):\n",
    "        geom = self.geom\n",
    "        \n",
    "        if isinstance(geom, MultiPolygon):\n",
    "            geompoly = calculate_max_area_geom(geom)\n",
    "        elif isinstance(geom, Polygon):\n",
    "            geompoly = geom\n",
    "\n",
    "        return np.array((geompoly.exterior.coords))\n",
    "    \n",
    "    def calculate_lengths(self):\n",
    "        return np.sqrt((np.diff(self.vertices, axis=0)**2).sum(axis=1))\n",
    "    \n",
    "    def calculate_vector(self):\n",
    "        # Returns column vector of the vertices (x0, y0, x1, y1, ...)\n",
    "        return self.vertices.reshape(len(self.vertices)*2, 1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77824d0b-3a36-41bb-ae72-546268cf028e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_geometry(current_state, uncertainties):\n",
    "    \n",
    "    maxlength = current_state.lengths.max()\n",
    "    \n",
    "    sampled_vertices = []\n",
    "    \n",
    "    # Choose a random direction\n",
    "    theta = random.uniform(0,2*np.pi)\n",
    "\n",
    "    for (x,y), sigma in zip(current_state.vertices, uncertainties):\n",
    "        mu=0\n",
    "        # randx = random.gauss(mu, sigma)\n",
    "        # randy = random.gauss(mu, sigma)\n",
    "        \n",
    "        # Choose a normal random radius based on the given sigma\n",
    "        radius = abs(random.gauss(mu, sigma))\n",
    "        \n",
    "        # Calculate x and y distance for the random\n",
    "        randx = radius*np.cos(theta)\n",
    "        randy = radius*np.sin(theta)\n",
    "        \n",
    "        sampled_vertices.append((x+randx, y+randy))\n",
    "\n",
    "    sampled_vertices = np.array(sampled_vertices)\n",
    "    # return Polygon(sampled_vertices).buffer(maxlength, join_style=1).buffer(-maxlength, join_style=1)\n",
    "    return Polygon(sampled_vertices)\n",
    "\n",
    "\n",
    "def interpolate_geometries(geoms, vertex_count = None):\n",
    "    \n",
    "    if vertex_count == None:\n",
    "        vertex_count = 0\n",
    "        for geom in geoms:\n",
    "            if isinstance(geom, MultiPolygon):\n",
    "                geom = calculate_max_area_geom(geom)\n",
    "\n",
    "            if vertex_count < len(geom.exterior.coords):\n",
    "                vertex_count = len(geom.exterior.coords)\n",
    "\n",
    "    interpolated_vertices = []\n",
    "    for geom in geoms:\n",
    "        if isinstance(geom, MultiPolygon):\n",
    "            geom = calculate_max_area_geom(geom)\n",
    "        \n",
    "        geom_state = State(geom)\n",
    "        vertices = np.array(interpolate_perimeter(geom_state.calculate_vertices(), vertex_count))\n",
    "\n",
    "        interpolated_vertices.append(vertices)\n",
    "        \n",
    "    return interpolated_vertices\n",
    "\n",
    "\n",
    "def align_vertices(interpolated_vertices):\n",
    "\n",
    "    time_estimator = TimeEstimator(len(interpolated_vertices)-1)\n",
    "\n",
    "    minroll_lst = []\n",
    "    \n",
    "    aligned_vertices = [interpolated_vertices[0]]\n",
    "    for i in range(len(interpolated_vertices)-1):\n",
    "        print(time_estimator.info_str(i), end='\\r', flush=True)\n",
    "\n",
    "        right_vertices = interpolated_vertices[i+1]\n",
    "\n",
    "\n",
    "        # Cycle right_vertices\n",
    "        l2perroll = []\n",
    "        for roll in range(len(interpolated_vertices[i])-1):\n",
    "            diff = aligned_vertices[0] - right_vertices\n",
    "            diff2sum = (diff[:,0]**2 + diff[:,1]**2).sum()\n",
    "\n",
    "            # Calculate diff^2 in\n",
    "            l2perroll.append(diff2sum)\n",
    "\n",
    "            right_vertices = np.roll(right_vertices,1, axis=0)\n",
    "\n",
    "        minroll_lst.append(np.argmin(l2perroll))\n",
    "\n",
    "    for i in range(len(interpolated_vertices)-1):\n",
    "        aligned_vertices.append(np.roll(interpolated_vertices[i+1], minroll_lst[i], axis=0))\n",
    "    \n",
    "    return aligned_vertices\n",
    "## Check reverse direction too?\n",
    "\n",
    "def create_ensembles(nsamples, current_state, windspeed, winddirection, normalized_scale, filetype, objectid, datetime, description):\n",
    "                     \n",
    "    # uncertainty in both x and y for each vertex\n",
    "    # uncertainties = calculate_uncertainties_observed(current_state.vertices, windspeed, winddirection, scale=windspeed*normalized_scale)*np.sqrt(current_state.lengths.sum())\n",
    "    uncertainties = calculate_uncertainties_observed(current_state.vertices, windspeed, winddirection, scale=1)\n",
    "\n",
    "    ignitions = {'igniteidx': [], \n",
    "                 'filetype': [],\n",
    "                 'objectid': [],\n",
    "                 'filepath': [],\n",
    "                 'datetime': [],\n",
    "                 'description': [],\n",
    "                 'geometry': []}\n",
    "\n",
    "    time_estimator = TimeEstimator(nsamples)\n",
    "    for sample in range(nsamples):\n",
    "        print(time_estimator.info_str(sample), end='\\r', flush=True)\n",
    "        \n",
    "        igniteidx = uuid.uuid4().hex\n",
    "        ignitions['igniteidx'].append(igniteidx)\n",
    "        ignitions['filetype'].append(filetype)\n",
    "        ignitions['objectid'].append(f'{objectid}E{sample:04d}')\n",
    "\n",
    "        geometry = sample_geometry(current_state, uncertainties)\n",
    "        if isinstance(geometry, MultiPolygon):\n",
    "            geometry = calculate_max_area_geom(geometry)\n",
    "\n",
    "        ignitions['geometry'].append(geometry)\n",
    "\n",
    "        ignitions['filepath'].append(f'{usr.db.fp.datadir}ignitions/{selected_fire}E{igniteidx}.shp')\n",
    "        gpd.GeoDataFrame({'FID': [0], 'geometry': ignitions['geometry'][-1]}, \n",
    "                         crs='EPSG:5070').to_file(ignitions['filepath'][-1])\n",
    "\n",
    "        ignitions['datetime'].append(datetime)\n",
    "        ignitions['description'].append(description)\n",
    "        \n",
    "    return ignitions\n",
    "\n",
    "\n",
    "def create_ensemble_matrix(geoms, vertex_count=100, aligned_geom=None):\n",
    "\n",
    "    interpolated_vertices = interpolate_geometries(geoms, vertex_count=vertex_count)\n",
    "    # Add first list of vertices from the state vector to align. align_vertices aligns all the perimeters w.r.t the first array\n",
    "    if aligned_geom is not None:\n",
    "        interpolated_vertices = [aligned_geom] + interpolated_vertices\n",
    "\n",
    "    aligned_vertices = align_vertices(interpolated_vertices)\n",
    "    if aligned_geom is not None:\n",
    "        aligned_vertices = aligned_vertices[1:]\n",
    "    else:\n",
    "        aligned_geom = aligned_vertices[0]\n",
    "    \n",
    "    if vertex_count is None:\n",
    "        vertex_count = aligned_vertices[0].shape[0]\n",
    "    \n",
    "    X = np.zeros((vertex_count*2, nsamples))\n",
    "    for i, vertices in enumerate(aligned_vertices):\n",
    "        X[:,i] = vertices.flatten()\n",
    "        \n",
    "    return X, aligned_geom, vertex_count\n",
    "\n",
    "\n",
    "def state_to_ignitions(X_0, objectid_lst, datetime_lst, description_lst, filetype_lst, usr):\n",
    "\n",
    "    geoms = [Polygon(zip(X_0[::2,i], X_0[1::2,i])).buffer(0) for i in range(X_0.shape[1])]\n",
    "\n",
    "    ignitions = {'igniteidx': [],\n",
    "                 'filetype': [],\n",
    "                 'objectid': [],\n",
    "                 'filepath': [],\n",
    "                 'geometry': [],\n",
    "                 'datetime': [],\n",
    "                 'description': []}\n",
    "\n",
    "    for sample, geometry in enumerate(geoms):\n",
    "        filetype = filetype_lst[sample]\n",
    "        datetime = datetime_lst[sample]\n",
    "        description = description_lst[sample]\n",
    "        objectid = objectid_lst[sample]\n",
    "        \n",
    "        igniteidx = uuid.uuid4().hex\n",
    "        ignitions['igniteidx'].append(igniteidx)\n",
    "        ignitions['filetype'].append(filetype)\n",
    "        ignitions['objectid'].append(f'{objectid}U{sample:04d}')\n",
    "\n",
    "        if isinstance(geometry, MultiPolygon):\n",
    "            geometry = calculate_max_area_geom(geometry)\n",
    "\n",
    "        ignitions['geometry'].append(geometry)\n",
    "\n",
    "        ignitions['filepath'].append(f'{usr.db.fp.datadir}ignitions/{description}U{sample:04d}_{igniteidx}.shp')\n",
    "        gpd.GeoDataFrame({'FID': [0], 'geometry': ignitions['geometry'][-1]}, \n",
    "                         crs='EPSG:5070').to_file(ignitions['filepath'][-1])\n",
    "\n",
    "        ignitions['datetime'].append(datetime)\n",
    "        ignitions['description'].append(description)\n",
    "    \n",
    "    return ignitions\n",
    "\n",
    "def validate_geoms_matrix(X, aligned_geom):\n",
    "    for i in range(X.shape[1]):\n",
    "        X_0 = X[:,i]\n",
    "        x = X_0[::2]\n",
    "        y = X_0[1::2]\n",
    "\n",
    "        geom = Polygon(zip(x,y)).buffer(0)\n",
    "        if isinstance(geom, MultiPolygon):\n",
    "            geom = calculate_max_area_geom(geom)\n",
    "\n",
    "        xx,yy = geom.exterior.xy\n",
    "        xx = list(xx)\n",
    "        yy = list(yy)\n",
    "\n",
    "        geom = np.array(interpolate_perimeter(list(zip(xx, yy)), len(x)))\n",
    "        geom = align_vertices([aligned_geom, geom])[1]\n",
    "\n",
    "        X[:,i] = geom.flatten()\n",
    "\n",
    "    return X\n",
    "\n",
    "def recalculate_ignition(mainapi):\n",
    "    runfile = mainapi.runfile_lst[0]\n",
    "    geom = gpd.read_file(runfile.ignitepath)['geometry'][0]\n",
    "    state = State(geom)\n",
    "    uncertainties = calculate_uncertainties_observed(state.vertices, runfile.windspeed, runfile.winddirection, scale=1)\n",
    "    geom1 = sample_geometry(state, uncertainties).buffer(0)\n",
    "    gpd.GeoDataFrame({'FID': [0], 'geometry': geom1}, crs='EPSG:5070').to_file(runfile.ignitepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3f538e-2e16-4561-baab-2d18133bc96b",
   "metadata": {},
   "source": [
    "### Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a0ee5d-c9bd-42da-ba45-6ed47237b2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_perimeters(alst, colors='rgbcmyk', showvertex = 0):\n",
    "    fig, ax = plt.subplots(1,1, figsize=(4,2), dpi=200)\n",
    "    \n",
    "    for a,c in zip(alst, colors):\n",
    "        if c == 'r':\n",
    "            ax.plot(a[::2], a[1::2], c+'o', markersize=1)\n",
    "        else:\n",
    "            ax.plot(a[::2], a[1::2], c)\n",
    "            \n",
    "        ax.scatter(a[2*showvertex], a[2*showvertex + 1], facecolor=(0,0,0,0.2), edgecolor=(0,0,0,0.9))\n",
    "        \n",
    "    ax.set_ylim(1.502e6, 1.506e6)\n",
    "    ax.set_xlim(-2.087e6, -2.081e6)\n",
    "    \n",
    "def compare_matrices(X, colors='rgbcmy', showvertex = 0, ax=None):\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1,1, figsize=(4,2), dpi=200)\n",
    "    \n",
    "    for i in range(X.shape[1]):\n",
    "        c = colors[i%len(colors)]\n",
    "        ax.plot(X[::2,i], X[1::2,i], c)\n",
    "        ax.scatter(X[2*showvertex,i], X[2*showvertex+1,i], facecolor=(0,0,0,0.2), edgecolor=(0,0,0,0.9))\n",
    "        \n",
    "    # ax.set_ylim(1.502e6, 1.506e6)\n",
    "    # ax.set_xlim(-2.087e6, -2.081e6)\n",
    "    \n",
    "    return ax\n",
    "\n",
    "def plot_geometry(geom, ax, **kwargs):\n",
    "    if isinstance(geom, MultiPolygon):\n",
    "        for g in geom.geoms:\n",
    "            x,y = g.exterior.coords.xy\n",
    "            ax.plot(x,y, **kwargs)\n",
    "    else:\n",
    "        x,y = geom.exterior.coords.xy\n",
    "        ax.plot(x,y, **kwargs)\n",
    "        \n",
    "def plot_matrix(X, ax, show_stdev = False, **kwargs):\n",
    "    vcounts = X.shape[0]//2\n",
    "    \n",
    "    color = (1,0,0,0.9)\n",
    "    if 'color' in kwargs:\n",
    "        color = kwargs['color']\n",
    "        \n",
    "    X_std = np.std(X, axis=1)\n",
    "    X_mean = np.mean(X, axis=1)\n",
    "    ax.plot(X_mean[::2], X_mean[1::2], **kwargs)\n",
    "\n",
    "    # Calculate standard deviation of the generated coordinates\n",
    "    x0, y0 = X_mean[::2], X_mean[1::2]\n",
    "    radstd = np.zeros_like(x0)\n",
    "    \n",
    "    for vix in range(vcounts):\n",
    "        x,y = X[2*vix,:], X[2*vix+1,:]\n",
    "        radius = np.sqrt((x-x0[vix])**2 +(y-y0[vix])**2)\n",
    "        radstd[vix] = np.std(radius)\n",
    "    \n",
    "    if show_stdev:\n",
    "        for vix in range(vcounts):\n",
    "            circle = plt.Circle((x0[vix], y0[vix]), radius=radstd[vix], fill=False, edgecolor=(0,0,0,0.4), lw=0.3)\n",
    "            ax.add_artist(circle)\n",
    "       \n",
    "def update_EnKF(Xt, Y, aligned_geom):\n",
    "    nsamples = Y.shape[1]\n",
    "\n",
    "    xt = Xt.mean(axis=1, keepdims=True)\n",
    "    y = Y.mean(axis=1, keepdims=True)\n",
    "\n",
    "    Ex = Xt - xt.repeat(nsamples, axis=1)\n",
    "    Ey = Y - y.repeat(nsamples, axis=1)\n",
    "\n",
    "    Py = 1/(nsamples-1)*np.matmul(Ey, Ey.T)\n",
    "    Pxy = 1/(nsamples-1)*np.matmul(Ex, Ey.T)\n",
    "\n",
    "    max_Py = abs(Py).max()\n",
    "    max_Pxy = abs(Pxy).max()\n",
    "\n",
    "    Py /= max_Py\n",
    "    Pxy /= max_Pxy\n",
    "\n",
    "    Py_inv = np.linalg.pinv(Py, hermitian=True)\n",
    "\n",
    "    assert(np.allclose(np.matmul(Py_inv, Py), np.eye(Y.shape[0]))), 'Inverse calculation is incorrect'\n",
    "\n",
    "    K = np.matmul(Pxy, Py_inv)*(max_Pxy/max_Py)\n",
    "\n",
    "    #### Update the state ensemble\n",
    "    X = Xt + np.matmul(K, (Y - Xt))\n",
    "\n",
    "    ### TODO ####\n",
    "    # Fix invalid geometries\n",
    "\n",
    "    X = validate_geoms_matrix(X, aligned_geom)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b602a3-a491-4c35-8975-6e38df5648c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnKF:\n",
    "    # Initialize with the first observation\n",
    "    # Windspeed and direction is given from PyLaski\n",
    "    def __init__(self, observation: gpd.GeoSeries, windspeed: int, winddirection: int, normalized_scale: float, nsamples: int, usr: futils.User):\n",
    "        state_geom = gpd.read_file(observation['filepath'])['geometry'].set_crs(epsg=5070).iloc[0]\n",
    "        \n",
    "        \n",
    "        self.state_datetime = observation['datetime']\n",
    "        self.selected_fire = observation['description']\n",
    "        self.igniteidx = observation.name\n",
    "        self.current_state = State(state_geom)\n",
    "        \n",
    "        \n",
    "        self.windspeed = windspeed\n",
    "        self.winddirection = winddirection\n",
    "        self.normalized_scale = normalized_scale\n",
    "        self.nsamples = nsamples\n",
    "        self.usr = usr\n",
    "\n",
    "        self.ignitions = create_ensembles(self.nsamples, self.current_state, self.windspeed, self.winddirection, self.normalized_scale,\n",
    "                                     observation['filetype'], observation['objectid'],\n",
    "                                     observation['datetime'], observation['description'])\n",
    "        \n",
    "        self.usr.db.gdfignition = self.usr.db.gdfignition.append(gpd.GeoDataFrame(self.ignitions).set_index('igniteidx').set_crs(epsg=5070))\n",
    "        \n",
    "        # Create ensemble matrix\n",
    "        self.X_0, self.aligned_geom, self.vertex_count = create_ensemble_matrix(self.ignitions['geometry'])\n",
    "        \n",
    "    # Updates the state matrix\n",
    "    # Need to first add the observation into the database (usr.db for now)\n",
    "    def update(self, compareidx: str, lcpidx: str, barrieridx: str, observation: gpd.GeoSeries, windspeed: int, winddirection: int):\n",
    "        # Advance the state in Farsite using the windspeed and direction\n",
    "        inputData_lst = []\n",
    "        self.mainapi_lst = []\n",
    "        for igniteidx in self.ignitions['igniteidx']:\n",
    "            inputData = {'description': self.selected_fire,\n",
    "                         'igniteidx'  : igniteidx,\n",
    "                         'compareidx' : compareidx,\n",
    "                         'lcpidx'     : lcpidx,\n",
    "                         'barrieridx' : barrieridx,\n",
    "\n",
    "                         'windspeed': windspeed, 'winddirection': winddirection,\n",
    "                         'relhumid': 90, 'temperature': 20}\n",
    "\n",
    "            self.mainapi_lst.append(self.usr.calculatePerimeters(inputData))\n",
    "            \n",
    "\n",
    "        # from multiprocessing import Pool\n",
    "\n",
    "        # numproc = 4\n",
    "        # pool = Pool(processes=numproc)\n",
    "\n",
    "        # Run for each FarsiteManual\n",
    "        for mainapi in self.mainapi_lst:\n",
    "            # pool.apply_async(farsite.run_command, callback=farsite.updatedb)\n",
    "            mainapi.run_farsite()\n",
    "            runfile = mainapi.runfile_lst[0]\n",
    "            outperimpath = runfile.outpath+'_Perimeters.shp'\n",
    "            while len(gpd.read_file(outperimpath)) == 0:\n",
    "                recalculate_ignition(mainapi)\n",
    "                mainapi.run_farsite()\n",
    "            \n",
    "            \n",
    "\n",
    "        # pool.close()\n",
    "        # pool.join()\n",
    "        \n",
    "        # Filter igniteidx->compareidx simulations only\n",
    "        df = self.usr.db.gdfsimulation\n",
    "        filtered_indices = df[df['igniteidx'].isin(self.ignitions['igniteidx']) & (df['compareidx'] == compareidx)].index\n",
    "        \n",
    "        if (len(filtered_indices) != self.nsamples):\n",
    "            raise ValueError(f'Expecting {nsamples} simulation outputs, {len(filtered_indices)} found')\n",
    "        \n",
    "        self.Xt_1, self.aligned_geom, self.vertex_count = create_ensemble_matrix(df.loc[filtered_indices, 'geometry'], \n",
    "                                                                                 self.vertex_count, self.aligned_geom)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Calculate ensemble for the observation\n",
    "        state_geom = gpd.read_file(observation['filepath'])['geometry'].set_crs(epsg=5070).iloc[0]\n",
    "        # igniteidx = observation.name\n",
    "        state_datetime = observation['datetime']\n",
    "\n",
    "        self.observed_state = State(state_geom)\n",
    "\n",
    "        self.observed_ensemble = create_ensembles(self.nsamples, self.observed_state, windspeed, winddirection, self.normalized_scale,\n",
    "                                     observation['filetype'], observation['objectid'],\n",
    "                                     observation['datetime'], observation['description'])\n",
    "\n",
    "        self.Y_1, self.aligned_geom, self.vertex_count = create_ensemble_matrix(self.observed_ensemble['geometry'], self.vertex_count, self.aligned_geom)\n",
    "        self.Xt_1 = remove_duplicates(self.Xt_1, self.vertex_count)\n",
    "        self.Y_1 = remove_duplicates(self.Y_1, self.vertex_count)\n",
    "        \n",
    "        \n",
    "        self.X_1 = update_EnKF(self.Xt_1, self.Y_1, self.aligned_geom)\n",
    "        ##############################\n",
    "        # Calculate the Kalman Filter\n",
    "        ###############################\n",
    "\n",
    "        ####################\n",
    "        # Recursive updates\n",
    "        ##################\n",
    "        \n",
    "        # Update ignitions\n",
    "        self.X_0 = self.X_1\n",
    "        self.ignitions = state_to_ignitions(self.X_0, self.observed_ensemble['objectid'], self.observed_ensemble['datetime'], \n",
    "                           self.observed_ensemble['description'], self.observed_ensemble['filetype'], self.usr)\n",
    "        \n",
    "        self.current_state = self.observed_state\n",
    "        \n",
    "        self.usr.db.gdfignition = pd.concat([self.usr.db.gdfignition, gpd.GeoDataFrame(self.ignitions, geometry='geometry', crs='EPSG:5070').set_index('igniteidx')])\n",
    "        \n",
    "        # x_1 = X_1.mean(axis=1, keepdims=True)\n",
    "        \n",
    "# ## obtain the igniteidx of the ignition\n",
    "# ## The indices will be passed from the interface, which will include corresponding datetime, filepath etc.\n",
    "# compareidx = '9f82e870591748a9a8a01346d174f2a1'    # t=1 observation\n",
    "# lcpidx = '43b7f5db36994599861eec4849cc68fd'        # Index for Maria2019\n",
    "# barrieridx = 'cb47616cd2dc4ccc8fd523bd3a5064bb'    # NoBarrier shapefile index        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420243c5-5c30-4cb0-9deb-696df19bf38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_model(igniteidx_lst, compareidx, lcpidx, barrieridx, windspeed, winddirection, usr_model):\n",
    "    inputData = {'description': 'Maria2019',\n",
    "                 'igniteidx'  : igniteidx_lst[-1],\n",
    "                 'compareidx' : compareidx,\n",
    "                 'lcpidx'     : lcpidx,\n",
    "                 'barrieridx' : barrieridx,\n",
    "\n",
    "                 'windspeed': windspeed, 'winddirection': winddirection,\n",
    "                 'relhumid': 90, 'temperature': 20}\n",
    "\n",
    "    mainapi = usr_model.calculatePerimeters(inputData)\n",
    "    mainapi.run_farsite()\n",
    "\n",
    "    gdfsim = usr_model.db.gdfsimulation.iloc[-1]\n",
    "    gdfsim_geom = gdfsim['geometry']\n",
    "    if isinstance(gdfsim_geom, MultiPolygon):\n",
    "        gdfsim_geom = calculate_max_area_geom(gdfsim_geom)\n",
    "        \n",
    "    gdfsim_geom = gdfsim_geom.buffer(0)\n",
    "    \n",
    "    usr_model.db.gdfignition = pd.concat([usr_model.db.gdfignition, gpd.GeoDataFrame({'filetype': 'Ignition',\n",
    "                                                                                      'objectid': str(usr_model.db.gdfignition.loc[gdfsim['igniteidx']]['objectid']) + '_farsite',\n",
    "                                                                                      'filepath': gdfsim['filepath'],\n",
    "                                                                                      'datetime': gdfsim['datetime'],\n",
    "                                                                                      'description': gdfsim['description'],\n",
    "                                                                                      'geometry': gdfsim_geom}, index=[gdfsim.name])\n",
    "                                         ])\n",
    "    igniteidx_lst.append(gdfsim.name)\n",
    "    gpd.GeoDataFrame({'FID': [0], 'geometry':gdfsim_geom}, \n",
    "                     crs='EPSG:5070').to_file(gdfsim['filepath'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12b23a4-96b9-4bfd-80c2-ee513b3078f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_duplicates(arr):\n",
    "    tst = []\n",
    "    for rix in range(arr.shape[0]):\n",
    "        for rjx in range(rix+1, arr.shape[0]):\n",
    "            tst.append(arr[rix,:] - arr[rjx,:])\n",
    "\n",
    "    tst = np.array(tst)\n",
    "    tstsum = tst.sum(axis=1)\n",
    "    zeroix = np.where(np.abs(tstsum) == 0)[0]\n",
    "\n",
    "    i = 0\n",
    "    rixlst = []\n",
    "    rjxlst = []\n",
    "    for rix in range(arr.shape[0]):\n",
    "        for rjx in range(rix+1, arr.shape[0]):            \n",
    "            if i in zeroix:\n",
    "                print(f'{i} found at pair {rix}, {rjx}')\n",
    "            i += 1\n",
    "\n",
    "def remove_duplicates(arr, dnumber):\n",
    "    tst = []\n",
    "    for rix in range(arr.shape[0]):\n",
    "        for rjx in range(rix+1, arr.shape[0]):\n",
    "            tst.append(arr[rix,:] - arr[rjx,:])\n",
    "\n",
    "    tst = np.array(tst)\n",
    "    tstsum = tst.sum(axis=1)\n",
    "    zeroix = np.where(np.abs(tstsum) == 0)[0]\n",
    "\n",
    "    i = 0\n",
    "    rixlst = []\n",
    "    rjxlst = []\n",
    "    for rix in range(arr.shape[0]):\n",
    "        for rjx in range(rix+1, arr.shape[0]):            \n",
    "            if i in zeroix:\n",
    "                # print(f'{i} found at pair {rix}, {rjx}')\n",
    "                rixlst.append(rix)\n",
    "                rjxlst.append(rjx)\n",
    "            i += 1\n",
    "\n",
    "    arrnew = np.zeros_like(arr)\n",
    "    arr = np.delete(arr, rixlst, axis=0)\n",
    "\n",
    "    for j in range(arr.shape[1]):\n",
    "        vertices = list(zip(arr[::2,j], arr[1::2,j]))\n",
    "        vertices_interpolated = interpolate_perimeter(vertices, dnumber)\n",
    "\n",
    "        arrnew[:,j] = np.array(vertices_interpolated).flatten()\n",
    "\n",
    "    return arrnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbdc110-72d4-4274-9dd2-7e8f37b6b89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial params\n",
    "\n",
    "initial = usr.db.gdfignition.iloc[0]\n",
    "windspeed = 10   # Calculations are made with windspeed = 10, winddirection = 90\n",
    "winddirection = 60\n",
    "nsamples = 250\n",
    "normalized_scale = 2\n",
    "\n",
    "state = EnKF(initial, windspeed, winddirection, normalized_scale, nsamples, usr)\n",
    "X_0_lst = [state.X_0]\n",
    "\n",
    "usr_model = futils.User(fp)\n",
    "# igniteidx_lst = ['f23196b034474744bdca7df94b13e0f7']\n",
    "igniteidx_lst = [referenceidx_lst[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e9c42a-a82c-4443-b011-5dd96885a8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(4,4), dpi=200)\n",
    "plot_matrix(X_0_lst[0], ax=ax, color='red', show_stdev=True)\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc7f936-1282-42b0-984a-a31ab7646409",
   "metadata": {},
   "source": [
    "### Testing EnKF update function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9e5bbb-177f-4523-81f8-f02f9a608705",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# N = 100\n",
    "# sigma = 50\n",
    "\n",
    "# srange = np.arange(10,1001, 10)\n",
    "# detlst = []\n",
    "\n",
    "# time_estimator = TimeEstimator(len(srange))\n",
    "# for i, s in enumerate(srange):\n",
    "#     print(time_estimator.info_str(i), end='\\r', flush=True)\n",
    "    \n",
    "#     mat = np.random.randn(N,s)*50\n",
    "#     P_mat = np.matmul(mat, mat.T)/(nsamples-1)\n",
    "#     P_mat = P_mat/P_mat.max()\n",
    "    \n",
    "#     detlst.append(np.linalg.det(P_mat))\n",
    "# # P_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2c9f1b-53bd-4f7a-be91-0ef3d7fa2c05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1,1, figsize=(3,2), dpi=200)\n",
    "# ax.plot(srange, detlst, 'k')\n",
    "# ax.set_ylim(0, 2e-6)\n",
    "\n",
    "# ax2 = ax.twinx()\n",
    "\n",
    "# ax2.semilogy(srange, detlst, 'r')\n",
    "# ax2.set_ylim(1e-50, 1e-5)\n",
    "# ax2.set_yticklabels(ax2.get_yticklabels(), color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74876d04-45a8-4760-967e-ceea1440ab27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# np.matmul(np.linalg.pinv(P_mat, hermitian=True), P_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca79278e-ce7c-4103-9c4c-0a44bca20834",
   "metadata": {},
   "source": [
    "### Test EnKF is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da16fec2-6b48-4f50-a44b-85863cb096f3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## obtain the igniteidx of the ignition\n",
    "## The indices will be passed from the interface, which will include corresponding datetime, filepath etc.\n",
    "lcpidx = '43b7f5db36994599861eec4849cc68fd'        # Index for Maria2019\n",
    "barrieridx = 'cb47616cd2dc4ccc8fd523bd3a5064bb'    # NoBarrier shapefile index\n",
    "\n",
    "# observation = usr.db.gdfignition.iloc[1]\n",
    "observation = usr.db.gdfignition.loc[referenceidx_lst[1]]\n",
    "compareidx = observation.name    # t=1 observation\n",
    "\n",
    "state.update(compareidx, lcpidx, barrieridx, observation, windspeed, winddirection)\n",
    "X_0_lst.append(state.X_0)\n",
    "\n",
    "calculate_model(igniteidx_lst, compareidx, lcpidx, barrieridx, windspeed, winddirection, usr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82e5dad-ee9e-42b3-86ef-0cfe539fa180",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(4,2), dpi=200)\n",
    "# plot_matrix(X_0_lst[0], ax=ax, color='blue')\n",
    "# plot_matrix(X_0_lst[1], ax=ax, color='black', show_stdev=True, label=r'$X$')\n",
    "plot_matrix(state.Xt_1, ax=ax, color='red', show_stdev=True, label=r'$X_t$')\n",
    "plot_matrix(state.Y_1, ax=ax, color='blue', show_stdev=True, label=r'$Y$')\n",
    "\n",
    "\n",
    "# ax.legend()\n",
    "ax.set_aspect('equal')\n",
    "# plt.imshow(state.Xt_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682e16ac-2e59-41c1-a5ff-fc115ec70d6b",
   "metadata": {},
   "source": [
    "### Testing second update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94b8bbf-53b6-4ef6-ad4d-5aadcbd62557",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ignitions = state.usr.db.gdfignition.loc[state.ignitions['igniteidx']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ad4e2a-3b70-48b8-ab01-e402f13f3ae6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46337fe-6cf1-4739-9f80-4c62ef22364e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 20\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(4,4), dpi=200)\n",
    "plot_geometry(gpd.read_file(ignitions.iloc[i]['filepath'])['geometry'][0], ax=ax, label='ignition')\n",
    "ax.plot(state.X_0[::2, i], state.X_0[1::2, i], 'r--')\n",
    "\n",
    "\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc5c83-323d-4a66-915d-6dc43d51849d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e77969b-d42d-46ea-98e5-161957a26af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d4cb95-2f9f-4e7e-b03a-565adfd97f80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9fb75a-7361-41ba-ab92-16cadeef05c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2806238b-6b88-4935-b0ed-001f312172cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "usr.db.gdfignition.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fdd0dd-9c6c-4a21-8a0c-a1f50dc31739",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283a3358-ab39-48db-915a-af395e4b537b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "i = 2\n",
    "observation = usr.db.gdfignition.loc[referenceidx_lst[i]]\n",
    "compareidx = observation.name    # t=1 observation\n",
    "\n",
    "state.update(compareidx, lcpidx, barrieridx, observation, windspeed, winddirection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb621b7-1735-4a92-a9e7-bf1b97d7757f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x,y = gpd.read_file(state.mainapi_lst[0].runfile_lst[0].outpath + '_Perimeters.shp')['geometry'][0].coords.xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e8349e-3eaa-4511-a26e-bab224e43795",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(4,4), dpi=200)\n",
    "plot_matrix(X_0_lst[1], ax=ax, color='blue')\n",
    "# plot_matrix(state.X_0[:,1:2], ax=ax)\n",
    "plot_matrix(state.Y_1, ax=ax, color='green', show_stdev=True)\n",
    "plot_matrix(state.Xt_1, ax=ax, color='blue', show_stdev=True)\n",
    "# ax.plot(x,y, 'k--', lw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e33408c-732d-406e-8882-8f473217a41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0_lst.append(state.X_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132b7871-4699-4cc1-8866-7822fa5e906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_model(igniteidx_lst, compareidx, lcpidx, barrieridx, windspeed, winddirection, usr_model)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eef0d2d-dab8-4da6-b732-80d87aa25fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# igniteidx_lst_model = igniteidx_lst.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61b04a6-2383-4630-b8e3-c4e14bdbc743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae721cf-881f-4edc-beac-b9e5b5760859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e815328c-498b-491f-a42c-c9ddb10be7e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b388f7-f7d5-49c7-b43d-894e3f79d722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5a9b1f-e310-4e4e-867d-aa9e34f20d71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 2\n",
    "observation = state.usr.db.gdfignition.iloc[i]\n",
    "compareidx = observation.name    # t=1 observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c68b8d8-ea2d-4b73-ad7a-2b66a7eb526d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpd.read_file(observation['filepath'])['geometry'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075838eb-d071-4b85-b842-20be76fed1fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "observation['geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe369c7-ac9a-463a-8831-d71a4a997937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advance the state in Farsite using the windspeed and direction\n",
    "inputData_lst = []\n",
    "state.mainapi_lst = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771cae0e-bce1-4c7e-8ca2-0f5c4c72ce3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "igniteidx = state.ignitions['igniteidx'][0]\n",
    "gpd.read_file(state.usr.db.gdfignition.loc[igniteidx, 'filepath'])['geometry'][0]\n",
    "\n",
    "inputData = {'description': state.selected_fire,\n",
    "             'igniteidx'  : igniteidx,\n",
    "             'compareidx' : compareidx,\n",
    "             'lcpidx'     : lcpidx,\n",
    "             'barrieridx' : barrieridx,\n",
    "\n",
    "             'windspeed': windspeed, 'winddirection': winddirection,\n",
    "             'relhumid': 90, 'temperature': 20}\n",
    "\n",
    "mainapi = state.usr.calculatePerimeters(inputData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c886e1fb-cb5a-4ab1-8994-dd5768914cb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mainapi.run_farsite()\n",
    "runfile = mainapi.runfile_lst[0]\n",
    "outperimpath = runfile.outpath+'_Perimeters.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748e9aae-6314-4c1c-9dcd-0ffb36278a63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpd.read_file(outperimpath)['geometry'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791219fc-9ea7-4d45-80ce-5ea5429a01fe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for mainapi in state.mainapi_lst:\n",
    "    # pool.apply_async(farsite.run_command, callback=farsite.updatedb)\n",
    "    mainapi.run_farsite()\n",
    "    runfile = mainapi.runfile_lst[0]\n",
    "    outperimpath = runfile.outpath+'_Perimeters.shp'\n",
    "    while len(gpd.read_file(outperimpath)) == 0:\n",
    "        recalculate_ignition(mainapi)\n",
    "        mainapi.run_farsite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c085b525-ec95-4274-a991-99f9a0cae76f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter igniteidx->compareidx simulations only\n",
    "df = state.usr.db.gdfsimulation\n",
    "filtered_indices = df[df['igniteidx'].isin(state.ignitions['igniteidx']) & (df['compareidx'] == compareidx)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7104247-cb97-482d-91a7-cbf5dea1b0b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_ensemble_matrix(df.loc[filtered_indices, 'geometry'], state.vertex_count, state.aligned_geom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eda260e-a7ee-4ea0-8419-b3e7c73e7b96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3b7021-a29d-4124-b517-a6ff242d33cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cff87ef-edb4-4b73-8d91-f21f8de67a90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b56f26-0822-48ee-82bc-912d09ef0f39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9e000d-8625-4e27-808d-cb536fbc3100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bcb785f-62ce-41fc-85bf-f13b90876f84",
   "metadata": {},
   "source": [
    "### Second update test is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8471ce03-e73c-427b-93b4-6948c1505f8d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "calc_range = range(2,10)\n",
    "time_estimator = TimeEstimator(len(calc_range))\n",
    "for i in calc_range:\n",
    "    print(time_estimator.info_str(i))\n",
    "    observation = usr.db.gdfignition.iloc[i]\n",
    "    compareidx = observation.name    # t=1 observation\n",
    "\n",
    "    state.update(compareidx, lcpidx, barrieridx, observation, windspeed, winddirection)\n",
    "    X_0_lst.append(state.X_0)\n",
    "\n",
    "    calculate_model(igniteidx_lst, compareidx, lcpidx, barrieridx, windspeed, winddirection, usr_model)\n",
    "    \n",
    "igniteidx_lst_model = igniteidx_lst.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b653b4-3e6d-4608-8e15-7208497ced1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484a9b95-0891-403b-8834-6a5bcb1311df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1,1, figsize=(4,4), dpi=200)\n",
    "# plot_matrix(X_0_lst[1], ax=ax, color='blue')\n",
    "# plot_matrix(X_0_lst[2][:,0:1], ax=ax, show_stdev=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961979dc-74b4-4f4c-8b87-80b826a724a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geopandas as gpd\n",
    "\n",
    "# gdf = gpd.read_file('/home/jovyan/data/ignitions/Maria2019U0081_f5421b23173641e18b5d780c6d528798.shp')\n",
    "# gdf['geometry'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387a1474-cf25-4198-b8f4-9c6c0c97ef3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(4,4), dpi=200)\n",
    "plot_matrix(state.Xt_1, ax=ax, show_stdev=True)\n",
    "\n",
    "# plt.imshow(state.Xt_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da16e4c-7441-4f71-997e-f38c89ab670c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfea16d2-b6fe-4975-b267-519c554609b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86668cd6-57cd-410d-816c-8526f4d90fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d635033-7453-4e12-9918-6b27477e8790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50579d8b-86ed-4dfb-a215-8ef9bca921d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f65f47-b4ea-4ad3-a82b-5086f30d864a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0054ba52-8832-42f4-8897-8eff14af83d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d3c62d-0ed8-4b8f-b9f4-a8e89891ee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1,1, figsize=(4,2), dpi=200)\n",
    "\n",
    "# # plot_matrix(X_0_lst[0], ax)\n",
    "# # plot_matrix(X_0_lst[1], ax, color='blue')\n",
    "# plot_matrix(X_0_lst[0], ax, color='black')\n",
    "# plot_matrix(X_0_lst[1], ax, color='black')\n",
    "# plot_matrix(X_0_lst[2], ax, color='black')\n",
    "# plot_matrix(X_0_lst[3], ax, color='black')\n",
    "# plot_matrix(X_0_lst[4], ax, color='black')\n",
    "# plot_matrix(X_0_lst[5], ax, color='black')\n",
    "# plot_matrix(X_0_lst[6], ax, color='black')\n",
    "# plot_geometry(usr.db.gdfignition.iloc[4]['geometry'], ax)\n",
    "# plot_geometry(usr.db.gdfignition.iloc[5]['geometry'], ax)\n",
    "# plot_geometry(usr.db.gdfignition.iloc[6]['geometry'], ax)\n",
    "# # plot_geometry(usr.db.gdfignition.iloc[10]['geometry'], ax)\n",
    "# # plot_geometry(usr.db.gdfignition.iloc[11]['geometry'], ax)\n",
    "# # plot_geometry(usr.db.gdfignition.iloc[12]['geometry'], ax)\n",
    "# # plot_geometry(usr.db.gdfignition.iloc[13]['geometry'], ax)\n",
    "# # plot_geometry(usr.db.gdfignition.iloc[14]['geometry'], ax)\n",
    "# # plot_geometry(usr.db.gdfignition.iloc[15]['geometry'], ax)\n",
    "# # plot_geometry(usr.db.gdfignition.iloc[16]['geometry'], ax)\n",
    "# # plot_geometry(usr.db.gdfignition.iloc[17]['geometry'], ax)\n",
    "# # plot_geometry(usr.db.gdfignition.iloc[18]['geometry'], ax)\n",
    "# # plot_geometry(usr.db.gdfignition.iloc[0]['geometry'], ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a44d97-9474-4b70-9c10-a281a2433f5b",
   "metadata": {},
   "source": [
    "## Compare the predictions from the updated states, observations and using only the first simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ed5f7b-ec68-4766-8b52-a3b9e59512a6",
   "metadata": {},
   "source": [
    "### 1. Predict with the updated states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d63fcf2-8519-472a-a4a9-47555d72221a",
   "metadata": {},
   "outputs": [],
   "source": [
    "usr_combined = futils.User(fp)\n",
    "igniteidx_lst = []\n",
    "compareidx_lst = []\n",
    "for i, X_0 in enumerate(X_0_lst):\n",
    "    obrow = usr.db.gdfignition.iloc[i]\n",
    "    comprow = usr.db.gdfignition.iloc[i+1]\n",
    "    \n",
    "    vertices = X_0.mean(axis=1)\n",
    "    geom = Polygon(zip(vertices[::2],vertices[1::2])).buffer(0)\n",
    "    \n",
    "    dt = obrow['datetime']\n",
    "    desc = obrow['description']\n",
    "    objid = str(obrow['objectid']) + '_updated'\n",
    "    ftype = obrow['filetype']\n",
    "    \n",
    "    ignitions = state_to_ignitions(X_0.mean(axis=1, keepdims=True), [objid], [dt], [desc], [ftype], usr_combined)\n",
    "    igniteidx_lst.append(ignitions['igniteidx'][0])\n",
    "    compareidx_lst.append(comprow.name)\n",
    "    \n",
    "    usr_combined.db.gdfignition = pd.concat([usr_combined.db.gdfignition, gpd.GeoDataFrame(ignitions, geometry='geometry', crs='EPSG:5070').set_index('igniteidx')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7aa856-4a61-49b9-b156-6e99d7012516",
   "metadata": {},
   "outputs": [],
   "source": [
    "igniteidx_lst_observed = []\n",
    "compareidx_lst_observed = []\n",
    "for i in range(len(igniteidx_lst)):\n",
    "    igniteidx_lst_observed.append(usr_combined.db.gdfignition.index[i])\n",
    "    compareidx_lst_observed.append(usr_combined.db.gdfignition.index[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bc07da-78a8-448d-8eb7-53b07cdf58e7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine all igniteidx and compareidx into a single\n",
    "\n",
    "igniteidx_lst_combined = igniteidx_lst + igniteidx_lst_observed\n",
    "compareidx_lst_combined = compareidx_lst + compareidx_lst_observed\n",
    "\n",
    "desc_lst_combined = ['Maria2019_updated' for i in range(len(igniteidx_lst))] + ['Maria2019_observed' for i in range(len(igniteidx_lst))]\n",
    "inputData_lst = []\n",
    "mainapi_lst = []\n",
    "for (igniteidx, compareidx, desc) in zip(igniteidx_lst_combined, compareidx_lst_combined, desc_lst_combined):\n",
    "    inputData = {'description': desc,\n",
    "                 'igniteidx'  : igniteidx,\n",
    "                 'compareidx' : compareidx,\n",
    "                 'lcpidx'     : '43b7f5db36994599861eec4849cc68fd',\n",
    "                 'barrieridx' : 'cb47616cd2dc4ccc8fd523bd3a5064bb',\n",
    "                 \n",
    "                 'windspeed': 10, 'winddirection': 60,\n",
    "                 'relhumid': 90, 'temperature': 20}\n",
    "    \n",
    "    mainapi_lst.append(usr_combined.calculatePerimeters(inputData))\n",
    "    \n",
    "for mainapi in mainapi_lst:\n",
    "    # pool.apply_async(farsite.run_command, callback=farsite.updatedb)\n",
    "    mainapi.run_farsite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6236ed-f53b-461c-b584-31ab53056e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usr_combined.db.gdfignition.to_pickle('/home/jovyan/ignitions.pkl')\n",
    "# usr_combined.db.gdfsimulation.to_pickle('/home/jovyan/simulations.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1debeb-3c1b-4c3f-9e20-82f32a063c6d",
   "metadata": {},
   "source": [
    "#### Interpolate all the vertices\n",
    "\n",
    "#### TODO: Vertices include an additional point when generated from geometry. Remove the repeat!\n",
    "\n",
    "#### TODO: Check whether the aligned_vertices have the correct roll amount\n",
    "1. Create matrices from the aligned_vertices, and form the $X_0$ ensemble state matrix\n",
    "2. Using the observation $y_1$, update the state vector and obtain $X_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfb7ebf-10e4-47b7-ba2d-d03e31d8e9f8",
   "metadata": {},
   "source": [
    "#### TODO - Question: Can we find a way to not interpolate the vertices\n",
    "1. Without interpolation, we need to create a matrix that maps the observed vertices to the state vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86c1968-48f0-4d52-900c-545ecc8a9cef",
   "metadata": {},
   "source": [
    "## Compare the perimeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6376ea2d-809c-4e9d-8140-80cff6fce841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdfignition = pd.read_pickle('/home/jovyan/ignitions.pkl')\n",
    "# gdfsimulation = pd.read_pickle('/home/jovyan/simulations.pkl')\n",
    "\n",
    "gdfignition = usr_combined.db.gdfignition\n",
    "gdfsimulation = usr_combined.db.gdfsimulation\n",
    "\n",
    "gdfignition_model = usr_model.db.gdfignition\n",
    "gdfsimulation_model = usr_model.db.gdfsimulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553df1e2-e6ca-40bf-b56d-f0d0a729c7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates(geom):\n",
    "    x,y = geom.exterior.coords.xy\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return x,y\n",
    "\n",
    "def calculate_rms(geom1, geom2):\n",
    "    xy1, xy2 = interpolate_geometries([geom1, geom2], vertex_count=2000)\n",
    "    xy1, xy2 = align_vertices([xy1, xy2])\n",
    "    return np.sqrt(np.sum((xy1[:,0] - xy2[:,0])**2 + (xy1[:,1] - xy2[:,1])**2)/xy1.shape[0])\n",
    "    \n",
    "\n",
    "def calculate_area_diff(geom1, geom2):\n",
    "    return (geom1.union(geom2) - geom1.intersection(geom2)).area\n",
    "\n",
    "calculate_error = calculate_area_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6c99d5-619d-456d-9bdc-a0c6c9fcd83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "geoms_updated = []\n",
    "geoms_observed = []\n",
    "geoms_compare = []\n",
    "geoms_model = []\n",
    "errors_updated = []\n",
    "errors_observed = []\n",
    "errors_model = []\n",
    "dt = []\n",
    "\n",
    "for compareidx in compareidx_lst[:-1]:\n",
    "    gdffiltered = gdfsimulation[gdfsimulation['compareidx'] == compareidx]\n",
    "    \n",
    "    geom_updated = gdffiltered[gdffiltered['description'] == 'Maria2019_updated']['geometry'].iloc[0]\n",
    "    if isinstance(geom_updated, MultiPolygon):\n",
    "        geom_updated = calculate_max_area_geom(geom_updated)\n",
    "    geoms_updated.append(geom_updated)\n",
    "    \n",
    "    geom_observed = gdffiltered[gdffiltered['description'] == 'Maria2019_observed']['geometry'].iloc[0]\n",
    "    if isinstance(geom_observed, MultiPolygon):\n",
    "        geom_observed = calculate_max_area_geom(geom_observed)\n",
    "    geoms_observed.append(geom_observed)\n",
    "    \n",
    "    geom_compare = gdfignition.loc[compareidx, 'geometry']\n",
    "    if isinstance(geom_compare, MultiPolygon):\n",
    "        geom_compare = calculate_max_area_geom(geom_compare)\n",
    "    geoms_compare.append(geom_compare)\n",
    "    \n",
    "    gdffiltered_model = gdfsimulation_model[gdfsimulation_model['compareidx'] == compareidx]\n",
    "    geom_model = gdffiltered_model[gdffiltered_model['description'] == 'Maria2019']['geometry'].iloc[0]\n",
    "    if isinstance(geom_model, MultiPolygon):\n",
    "            geom_model = calculate_max_area_geom(geom_model)\n",
    "    geoms_model.append(geom_model)\n",
    "    \n",
    "    dt.append((gdfignition.loc[compareidx, 'datetime'] - gdfignition.iloc[0]['datetime']).total_seconds()/60/60)\n",
    "    \n",
    "    errors_updated.append(calculate_error(geom_updated, geom_compare))\n",
    "    errors_observed.append(calculate_error(geom_observed,  geom_compare))\n",
    "    errors_model.append(calculate_error(geom_model, geom_compare))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872554e3-3b7f-4d7e-86f2-ea35cbf754a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1bcb05-e5b6-4164-9ef7-0160c382e529",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(4,3), dpi=400)\n",
    "ax.plot(dt, errors_updated, label='EnKF')\n",
    "ax.plot(dt, errors_observed, label='Observed')\n",
    "ax.plot(dt, errors_model, label='Model')\n",
    "\n",
    "ax.set_xlim(0,6)\n",
    "ax.set_ylim(0, 2.5e7)\n",
    "\n",
    "ax.set_xlabel('Hours after first ignition')\n",
    "ax.set_ylabel('Area difference')\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2675e95-8826-4ed9-870c-93a1443cf8a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5ff0dd-d763-4a0d-ad21-e8afac4882a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
